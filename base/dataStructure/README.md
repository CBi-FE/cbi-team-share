# 为什么要学习数据结构与算法

1.  大厂面试，数据结构和算法

2.  掌握数据结构和算法，不管对于阅读框架源码，还是理解其背后的设计思想，都是非常有用的。

如：每次查询时，从小到大排序所有的响应时间，如果总共有 1200 个数据，那第 1188 个数据就是 99% 的响应时间。
很显然，每次用这个方法查询的话都要排序，效率是非常低的。但是，如果你知道“堆”这个数据结构，用两个堆可以非常高效地解决这个问题。

堆排序的话，极值在堆顶 本题可以利用欲求解 99%响应时间，即查询由小到大 99%N 的响应时间，
也即由大到小 1%N 的响应时间，无论怎么说都是求第 `N` 大的时间 求第 `N` 大一般利用堆排序，
堆排序堆顶元素是极值（子堆亦然） 由题意可知，把最小的 `N` 个都放进堆里面，然后堆顶放最大的元素就可以了
即：所求为最大堆，每次入堆比堆顶元素小，就去掉堆顶，然后将该元素入堆

3.  基础架构设计，达到开源水平

架构设计思路都差不多，最后实现的功能也都差不多。但是有的人做出来的框架，Bug 很多、性能一般、扩展性也不好，只能在自己公司仅有的几个项目里面用一下。而有的人做的框架可以开源到 GitHub 上给很多人用，甚至被 Apache 收录。为什么会有这么大的差距呢？

我觉得，高手之间的竞争其实就在细节。这些细节包括：你用的算法是不是够优化，数据存取的效率是不是够高，内存是不是够节省等等。（1.算法够不够优化 -----> 时间复杂度低 2.数据存取效率是不是够高 -----> 响应快 3.内存是不是够节省 -----> 空间复杂度低）这些累积起来，决定了一个框架是不是优秀。
所以，如果你还不懂数据结构和算法，没听说过大 `O` 复杂度分析，不知道怎么分析代码的时间复杂度和空间复杂度

4.  总结

- 1.直接好处是能够有写出性能更优的代码。
- 2.算法，是一种解决问题的思路和方法，有机会应用到生活和事业的其他方面。
- 3.长期来看，大脑思考能力是个人最重要的核心竞争力，而算法是为数不多的能够有效训练大脑思考能力的途径之一。

# 什么是数据结构与算法

大部分数据结构和算法教材，在开篇都会给这两个概念下一个明确的定义。
但是，这些定义都很抽象，对理解这两个概念并没有实质性的帮助，反倒会让你陷入死抠定义的误区。毕竟，我们现在学习，并不是为了考试，所以，概念背得再牢，不会用也就没什么用。

## 广义上

数据结构就是指一组数据的存储结构。算法就是操作数据的一组方法。

数据是真正存在物理内存中的，在物理内存地址之上映射有线性内存地址，数据结构，算法都是基于线性内存地址的。
数据结构指的是在这个一维的线性地址上，怎么存放一条条的数据，是连着放，还是分开一块块地放，更好的数据结构能更好地组织内存地址空间。
算法指的就是怎么定位这个线性地址，更好的算法能更快地找到这个线性地址，找到这个数据。

## 狭义上

是指某些著名的数据结构和算法，比如队列、栈、堆、二分查找、动态规划等。这些都是前人智慧的结晶，我们可以直接拿来用

数据结构和算法是相辅相成的。数据结构是为算法服务的，算法要作用在特定的数据结构之上。

比如，因为数组具有随机访问的特点，常用的二分查找算法需要用数组来存储数据。但如果我们选择链表这种数据结构，二分查找算法就无法工作了，因为链表并不支持随机访问。

# 复杂度

## 什么是复杂度分析？

- 数据结构和算法解决是“如何让计算机更快时间、更省空间的解决问题”。
- 因此需从执行时间和占用空间两个维度来评估数据结构和算法的性能。
- 分别用时间复杂度和空间复杂度两个概念来描述性能问题，二者统称为复杂度。
- 复杂度描述的是算法执行时间（或占用空间）与数据规模的增长关系。

## 为什么要进行复杂度分析？

- 和性能测试相比，复杂度分析有不依赖执行环境、成本低、效率高、易操作、指导性强的特点。
- 掌握复杂度分析，将能编写出性能更优的代码，有利于降低系统开发和维护成本。

## 三、如何进行复杂度分析？

### 大 `O` 表示法

算法的执行效率，粗略地讲，就是算法代码执行的时间。但是，如何在不运行代码的情况下，用“肉眼”得到一段代码的执行时间呢？

比如下面这一段

```js
function cal(n) {
  let sum = 0;
  let i = 1;
  for (; i <= n; ++i) {
    sum = sum + i;
  }
  return sum;
}
```

从 CPU 的角度来看，这段代码的每一行都执行着类似的操作：读数据-运算-写数据。尽管每行代码对应的 CPU 执行的个数、执行的时间都不一样，但是，我们这里只是粗略估计，所以可以假设每行代码执行的时间都一样，为 `unit_time`（指的是指令周期）。在这个假设的基础之上，这段代码的总执行时间是多少呢？

第 2、3 行代码分别需要 1 个 `unit_time` 的执行时间，第 4、5 行都运行了 `n` 遍，所以需要 `2n*unit_time` 的执行时间，所以这段代码总的执行时间就是 `(2n+2)*unit_time`。可以看出来，所有代码的执行时间 `T(n)` 与每行代码的执行次数成正比。

再来看下面一段

```js
function cal(n) {
  let sum = 0;
  let i = 1;
  let j = 1;
  for (; i <= n; ++i) {
    j = 1;
    for (; j <= n; ++j) {
      sum = sum + i * j;
    }
  }
}
```

第 2、3、4 行代码，每行都需要 1 个 `unit*time` 的执行时间，第 5、6 行代码循环执行了 `n` 遍，需要 `2n * unit*time` 的执行时间，第 7、8 行代码循环执行了 `n2` 遍，所以需要 `2n2 * unit_time` 的执行时间。所以，整段代码总的执行时间 `T(n) = (2n²+2n+3)*unit_time`。

尽管我们不知道 unit_time 的具体值，但是通过这两段代码执行时间的推导过程，我们可以得到一个非常重要的规律，那就是，所有代码的执行时间 `T(n)` 与每行代码的执行次数 `f(n)` 成正比。

其中，`T(n)` 我们已经讲过了，它表示代码执行的时间；n 表示数据规模的大小；`f(n)` 表示每行代码执行的次数总和。因为这是一个公式，所以用 `f(n)` 来表示。公式中的 O，表示代码的执行时间 `T(n)` 与 `f(n)` 表达式成正比。

`f(n)` 是代码执行次数的总和 `O` 是执行总时间和总次数的比值，可以理解为执行每行代码的平均时间 总行数 × 每行平均时间 ＝ 总时间

#### 时间复杂度分析

1.  只关注循环执行次数最多的一段代码

大 `O` 这种复杂度表示方法只是表示一种变化趋势。我们通常会忽略掉公式中的常量、低阶、系数，只需要记录一个最大阶的量级就可以了。
所以，我们在分析一个算法、一段代码的时间复杂度的时候，也只关注循环执行次数最多的那一段代码就可以了。这段核心代码执行次数的 `n` 的量级，就是整段要分析代码的时间复杂度。

比如上面例子 1

```js
function cal(n) {
  let sum = 0;
  let i = 1;
  for (; i <= n; ++i) {
    sum = sum + i;
  }
  return sum;
}
```

其中第 2、3 行代码都是常量级的执行时间，与 `n` 的大小无关，所以对于复杂度并没有影响。循环执行次数最多的是第 4、5 行代码，所以这块代码要重点分析。前面我们也讲过，这两行代码被执行了 `n` 次，所以总的时间复杂度就是 `O(n)`。

2.  加法法则：总复杂度等于量级最大的那段代码的复杂度

```js
function cal(n) {
  let sum_1 = 0;
  let p = 1;
  for (; p < 100; ++p) {
    sum_1 = sum_1 + p;
  }

  let sum_2 = 0;
  let q = 1;
  for (; q < n; ++q) {
    sum_2 = sum_2 + q;
  }

  let sum_3 = 0;
  let i = 1;
  let j = 1;
  for (; i <= n; ++i) {
    j = 1;
    for (; j <= n; ++j) {
      sum_3 = sum_3 + i * j;
    }
  }

  return sum_1 + sum_2 + sum_3;
}
```

这个代码分为三部分，分别是求 sum_1、sum_2、sum_3。我们可以分别分析每一部分的时间复杂度，然后把它们放到一块儿，再取一个量级最大的作为整段代码的复杂度。

第一段的时间复杂度是多少呢？这段代码循环执行了 100 次，所以是一个常量的执行时间，跟 `n` 的规模无关。

这里再强调一下，即便这段代码循环 10000 次、100000 次，只要是一个已知的数，跟 `n` 无关，照样也是常量级的执行时间。当 `n` 无限大的时候，就可以忽略。尽管对代码的执行时间会有很大影响，但是回到时间复杂度的概念来说，它表示的是一个算法执行效率与数据规模增长的变化趋势，所以不管常量的执行时间多大，我们都可以忽略掉。因为它本身对增长趋势并没有影响。

那第二段代码和第三段代码的时间复杂度是多少呢？答案是 `O(n)` 和 `O(n²)`

综合这三段代码的时间复杂度，我们取其中最大的量级。所以，整段代码的时间复杂度就为 `O(n²)`。也就是说：总的时间复杂度就等于量级最大的那段代码的时间复杂度。那我们将这个规律抽象成公式就是：

如果 `T1(n)=O(f(n))`，`T2(n)=O(g(n))`；那么 `T(n)=T1(n)+T2(n)=max(O(f(n)), O(g(n))) =O(max(f(n), g(n)))`.

3.  乘法法则：嵌套代码的复杂度等于嵌套内外代码复杂度的乘积

如果 `T1(n)=O(f(n))`，`T2(n)=O(g(n))`；那么 `T(n)=T1(n)*T2(n)=O(f(n))*O(g(n))=O(f(n)_g(n))`.

也就是说，假设 `T1(n) = O(n)`，`T2(n) = O(n²)`，则 `T1(n) * T2(n) = O(n³)`。落实到具体的代码上，我们可以把乘法法则看成是嵌套循环，举个例子解释一下。

```js
function cal(n) {
  let ret = 0;
  let i = 1;
  for (; i < n; ++i) {
    ret = ret + f(i);
  }
}

function f(n) {
  let sum = 0;
  let i = 1;
  for (; i < n; ++i) {
    sum = sum + i;
  }
  return sum;
}
```

我们单独看 `cal()` 函数。假设 `f()` 只是一个普通的操作，那第 4 ～ 6 行的时间复杂度就是，`T1(n) = O(n)`。但 `f()` 函数本身不是一个简单的操作，它的时间复杂度是 `T2(n) = O(n)`，所以，整个 `cal()` 函数的时间复杂度就是，`T(n) = T1(n) * T2(n) = O(n*n) = O(n²)`。

#### 常见时间复杂度分析

对于刚罗列的复杂度量级，我们可以粗略地分为两类，多项式量级和非多项式量级。其中，非多项式量级只有两个：`O(2^n)` 和 `O(n!)`。
(由数和字母的积组成的代数式叫做单项式，单独的一个数或一个字母也叫做单项式。由若干个单项式相加组成的代数式叫做多项式。回忆一下数学上的定义)

我们把时间复杂度为非多项式量级的算法问题叫作 NP（Non-Deterministic Polynomial，非确定多项式）问题。

当数据规模 `n` 越来越大时，非多项式量级算法的执行时间会急剧增加，求解问题的执行时间会无限增长。所以，非多项式时间复杂度的算法其实是非常低效的算法。因此，关于 NP 时间复杂度我就不展开讲了。我们主要来看几种常见的多项式时间复杂度。

1.  `O(1)`

`O(1)` 只是常量级时间复杂度的一种表示方法，并不是指只执行了一行代码。比如这段代码，即便有 3 行，它的时间复杂度也是 `O(1）`，而不是 `O(3)`。

```js
const i = 8;
const j = 6;
const sum = i + j;
```

只要代码的执行时间不随 n 的增大而增长，这样代码的时间复杂度我们都记作 `O(1)`。或者说，一般情况下，只要算法中不存在循环语句、递归语句，即使有成千上万行的代码，其时间复杂度也是 `Ο(1)`。

2.  `O(logn)`、`O(nlogn)`

对数阶时间复杂度非常常见，同时也是最难分析的一种时间复杂度。我通过一个例子来说明一下。

```js
i = 1;
while (i <= n) {
  i = i * 2;
}
```

根据我们前面讲的复杂度分析方法，第三行代码是循环执行次数最多的。所以，我们只要能计算出这行代码被执行了多少次，就能知道整段代码的时间复杂度。
从代码中可以看出，变量 `i` 的值从 1 开始取，每循环一次就乘以 `2`。当大于 `n` 时，循环结束。还记得我们高中学过的等比数列吗？实际上，变量 `i` 的取值就是一个等比数列。如果我把它一个一个列出来，就应该是这个样子的：

2⁰ 2¹ 2² 2³ ... `2^x` = n

所以，我们只要知道 `x` 值是多少，就知道这行代码执行的次数了。通过 `2^x=n` 求解 `x` 这个问题我们想高中应该就学过了。`x=log₂n`，所以，这段代码的时间复杂度就是 `O(log₂n)`。

现在，把代码稍微改下，你再看看，这段代码的时间复杂度是多少？

```js
i = 1;
while (i <= n) {
  i = i * 3;
}
```

根据我刚刚讲的思路，很简单就能看出来，这段代码的时间复杂度为 `O(log₃n)`。实际上，不管是以 2 为底、以 3 为底，还是以 10 为底，我们可以把所有对数阶的时间复杂度都记为 `O(logn)`。为什么呢？

实际上，不管是以 2 为底、以 3 为底，还是以 10 为底，我们可以把所有对数阶的时间复杂度都记为 `O(logn)`。为什么呢？

我们知道，对数之间是可以互相转换的，`log₃n` 就等于 `log₃2 * log₂n`，所以 `O(log₃n) = O(C * log₂n)`，其中 C=log₃2 是一个常量。基于我们前面的一个理论：**在采用大 `O` 标记复杂度的时候，可以忽略系数，即 `O(Cf(n)) = O(f(n))`**。所以，`O(log₂n)` 就等于 `O(log₃n)`。因此，在对数阶时间复杂度的表示方法里，我们忽略对数的“底”，统一表示为 `O(logn)`。

回顾前面讲的 `O(logn)`，那 `O(nlogn)` 就很容易理解了。如果一段代码的时间复杂度是 `O(logn)`，我们循环执行 `n` 遍，时间复杂度就是 `O(nlogn)` 了。而且，`O(nlogn)` 也是一种非常常见的算法时间复杂度。比如，归并排序、快速排序的时间复杂度都是 O(nlogn)。

3.  `O(m+n)、O(m*n)`
    我们再来讲一种跟前面都不一样的时间复杂度，代码的复杂度由两个数据的规模来决定

```js
function cal(m, n) {
  let sum1 = 0;
  let i = 1;
  for (; i < m; ++i) {
    sum1 = sum1 + i;
  }
  let sum2 = 0;
  let j = 1;
  for (; j < n; ++j) {
    sum2 = sum2 + j;
  }
  return sum1 + sum2;
}
```

从代码中可以看出，m 和 n 是表示两个数据规模。我们无法事先评估 m 和 n 谁的量级大，所以我们在表示复杂度的时候，就不能简单地利用加法法则，省略掉其中一个。所以，上面代码的时间复杂度就是 O(m+n)。

针对这种情况，原来的加法法则就不正确了，我们需要将加法规则改为：`T1(m) + T2(n) = O(f(m) + g(n))`。但是乘法法则继续有效：`T1(m) * T2(n) = O(f(m) * f(n))`。

#### 空间复杂度分析

时间复杂度的全称是**渐进时间复杂度，表示算法的执行时间与数据规模之间的增长关系**。类比一下，空间复杂度全称就是**渐进空间复杂度**（asymptotic space complexity），**表示算法的存储空间与数据规模之间的增长关系**。

具体的例子来说明。（这段代码有点“傻”，一般没人会这么写）

```js
function print(n) {
  let i = 0;
  const a = new Array(n);
  for (i; i < n; ++i) {
    a[i] = i * i;
  }

  for (i = n - 1; i >= 0; --i) {
    console.log(a[i]);
  }
}
```

跟时间复杂度分析一样，我们可以看到，第 2 行代码中，我们申请了一个空间存储变量 `i`，但是它是常量阶的，跟数据规模 `n` 没有关系，所以我们可以忽略。第 3 行申请了一个大小为 `n` 的数组，除此之外，剩下的代码都没有占用更多的空间，所以整段代码的空间复杂度就是 `O(n)`。

我们常见的空间复杂度就是 `O(1)`、`O(n)`、`O(n²)`，像 `O(logn)`、`O(nlogn)` 这样的对数阶复杂度平时都用不到。而且，空间复杂度分析比时间复杂度分析要简单很多

#### 总结

- 来源
  算法的执行时间与每行代码的执行次数成正比，用 `T(n) = O(f(n))`表示，其中 `T(n)`表示算法执行总时间，`f(n)`表示每行代码执行总次数，而 `n` 往往表示数据的规模。

- 特点
  以时间复杂度为例，由于时间复杂度描述的是算法执行时间与数据规模的增长变化趋势，所以常量阶、低阶以及系数实际上对这种增长趋势不产决定性影响，所以在做时间复杂度分析时忽略这些项。

### 复杂度分析法则

- 单段代码看高频：比如循环。
- 多段代码取最大：比如一段代码中有单循环和多重循环，那么取多重循环的复杂度。
- 嵌套代码求乘积：比如递归、多重循环等
- 多个规模求加法：比如方法有两个参数控制两个循环的次数，那么这时就取二者复杂度相加。

## 常用的复杂度级别？

- 多项式阶：随着数据规模的增长，算法的执行时间和空间占用，按照多项式的比例增长。包括， `O(1)`（常数阶）、`O(logn)`（对数阶）、`O(n)`（线性阶）、`O(nlogn)`（线性对数阶）、`O(n^2)`（平方阶）、`O(n^3)`（立方阶）
- 非多项式阶：随着数据规模的增长，算法的执行时间和空间占用暴增，这类算法性能极差。包括， `O(2^n)`（指数阶）、`O(n!)`（阶乘阶）

## 浅析最好、最坏、平均、均摊时间复杂度

最好情况时间复杂度（best case time complexity）、最坏情况时间复杂度（worst case time complexity）、平均情况时间复杂度（average case time complexity）、均摊时间复杂度（amortized time complexity）。如果这几个概念你都能掌握，那对你来说，复杂度分析这部分内容就没什么大问题了。

### 最好、最坏情况时间复杂度

```js
// n表示数组array的长度
function find(array, n, x) {
  let i = 0;
  let pos = -1;
  for (; i < n; ++i) {
    if (array[i] == x) pos = i;
  }
  return pos;
}
```

这段代码要实现的功能是，在一个无序的数组（array）中，查找变量 `x` 出现的位置。如果没有找到，就返回 -1。按照上面讲的分析方法，这段代码的复杂度是 `O(n)`，其中，n 代表数组的长度。

我们在数组中查找一个数据，并不需要每次都把整个数组都遍历一遍，因为有可能中途找到就可以提前结束循环了。但是，这段代码写得不够高效。我们可以这样优化一下这段查找代码。

```js
// n表示数组array的长度
function find(array, n, x) {
  let i = 0;
  let pos = -1;
  for (; i < n; ++i) {
    if (array[i] == x) {
      pos = i;
      break;
    }
  }
  return pos;
}
```

这个时候，问题就来了。我们优化完之后，这段代码的时间复杂度还是 `O(n)` 吗？

因为，要查找的变量 x 可能出现在数组的任意位置。如果数组中第一个元素正好是要查找的变量 `x`，那就不需要继续遍历剩下的 `n-1` 个数据了，那时间复杂度就是 `O(1)`。但如果数组中不存在变量 `x`，那我们就需要把整个数组都遍历一遍，时间复杂度就成了 `O(n)`。所以，不同的情况下，这段代码的时间复杂度是不一样的。

为了表示代码在不同情况下的不同时间复杂度，我们需要引入三个概念：最好情况时间复杂度、最坏情况时间复杂度和平均情况时间复杂度。

顾名思义，最好情况时间复杂度就是，在最理想的情况下，执行这段代码的时间复杂度。就像我们刚刚讲到的，在最理想的情况下，要查找的变量 `x` 正好是数组的第一个元素，这个时候对应的时间复杂度就是最好情况时间复杂度。

同理，最坏情况时间复杂度就是，在最糟糕的情况下，执行这段代码的时间复杂度。就像刚举的那个例子，如果数组中没有要查找的变量 `x`，我们需要把整个数组都遍历一遍才行，所以这种最糟糕情况下对应的时间复杂度就是最坏情况时间复杂度。

### 平均情况时间复杂度

我们都知道，最好情况时间复杂度和最坏情况时间复杂度对应的都是极端情况下的代码复杂度，发生的概率其实并不大。为了更好地表示平均情况下的复杂度，我们需要引入另一个概念：平均情况时间复杂度，后面我简称为平均时间复杂度。

要查找的变量 x 在数组中的位置，有 n`+1` 种情况：在数组的 `0 ～ n-1` 位置中和不在数组中。我们把每种情况下，查找需要遍历的元素个数累加起来，然后再除以 `n+1`，就可以得到需要遍历的元素个数的平均值，即：
`(1+ 2 +3 + .... + n + n) / (n+1) = n(n+3)/2(n+1)`

时间复杂度的大 `O` 标记法中，可以省略掉系数、低阶、常量，所以，把刚刚这个公式简化之后，得到的平均时间复杂度就是 `O(n)`。

这个结论虽然是正确的，但是计算过程稍微有点儿问题。究竟是什么问题呢？我们刚讲的这 n+1 种情况，出现的概率并不是一样的。（这里要稍微用到一点儿概率论的知识）

我们知道，要查找的变量 `x`，要么在数组里，要么就不在数组里。这两种情况对应的概率统计起来很麻烦，
为了方便理解，我们假设在数组中与不在数组中的概率都为 1/2。另外，要查找的数据出现在 `0 ～ n-1` 这 n 个位置的概率也是一样的，为 `1/n`。所以，根据概率乘法法则，要查找的数据出现在 `0 ～ n-1` 中任意位置的概率就是 `1/(2n)`。

因此，前面的推导过程中存在的最大问题就是，没有将各种情况发生的概率考虑进去。如果我们把每种情况发生的概率也考虑进去，那平均时间复杂度的计算过程就变成了这样：

`1 * 1/2n + 2 * 1/2n + ... + n * 1/2n + n * 1/2 = ( 3n + 1 ) /4`

这个值就是概率论中的**加权平均值**，也叫作**期望值**，所以平均时间复杂度的全称应该叫**加权平均时间复杂度**或者**期望时间复杂度**。

引入概率之后，前面那段代码的加权平均值为 (3n+1)/4。(ps:等差求和公式:n(n+1)/2) 用大 `O` 表示法来表示，去掉系数和常量，这段代码的加权平均时间复杂度仍然是 `O(n)`。

你可能会说，平均时间复杂度分析好复杂啊，还要涉及概率论的知识。实际上，在大多数情况下，我们并不需要区分最好、最坏、平均情况时间复杂度三种情况。
很多时候，我们使用一个复杂度就可以满足需求了。只有同一块代码在不同的情况下，时间复杂度有量级的差距，我们才会使用这三种复杂度表示法来区分。

### 均摊时间复杂度

还有一个更加高级的概念，均摊时间复杂度，以及它对应的分析方法，摊还分析（或者叫平摊分析）。
（ps:均摊时间复杂度：amortized time complexity，对应的分析方法为摊还分析或者平摊分析）

均摊时间复杂度，听起来跟平均时间复杂度有点儿像。对于初学者来说，这两个概念确实非常容易弄混。
大部分情况下，我们并不需要区分最好、最坏、平均三种复杂度。平均复杂度只在某些特殊情况下才会用到，而均摊时间复杂度应用的场景比它更加特殊、更加有限。

```js
// array表示一个长度为n的数组
// 代码中的array.length就等于n
let array = new Array(n);
let count = 0;

function insert(val) {
  if (count == array.length) {
    let sum = 0;
    for (let i = 0; i < array.length; ++i) {
      sum = sum + array[i];
    }
    array[0] = sum;
    count = 1;
  }

  array[count] = val;
  ++count;
}
```

这段代码实现了一个往数组中插入数据的功能。当数组满了之后，也就是代码中的 `count == array.length` 时，
我们用 `for` 循环遍历数组求和，并清空数组，将求和之后的 `sum` 值放到数组的第一个位置，然后再将新的数据插入。但如果数组一开始就有空闲空间，则直接将数据插入数组。

可以先用我们刚讲到的三种时间复杂度的分析方法来分析一下。

最理想的情况下，数组中有空闲空间，我们只需要将数据插入到数组下标为 `count` 的位置就可以了，
所以最好情况时间复杂度为 `O(1)`。最坏的情况下，数组中没有空闲空间了，我们需要先做一次数组的遍历求和，然后再将数据插入，所以最坏情况时间复杂度为 `O(n)`。

那平均时间复杂度是多少呢？答案是 `O(1)`。我们还是可以通过前面讲的概率论的方法来分析。
(ps：这里是进行尾部插入，故大部分的复杂度都是 `O(1)`，只有小部分的复杂度为 `O(n)`)

假设数组的长度是 `n`，根据数据插入的位置的不同，我们可以分为 `n` 种情况，每种情况的时间复杂度是 `O(1)`。
除此之外，还有一种“额外”的情况，就是在数组没有空闲空间时插入一个数据，这个时候的时间复杂度是 `O(n)`。
而且，这 `n+1` 种情况发生的概率一样，都是 `1/(n+1)`。所以，根据加权平均的计算方法，我们求得的平均时间复杂度就是：

`1 * 1 / ( n + 1 ) + 1 * 1 / ( n + 1 ) + ... + 1 * 1 / ( n + 1 ) + n * 1 / ( n + 1 ) = O(1)`

至此为止，前面的最好、最坏、平均时间复杂度的计算，理解起来应该都没有问题。
但是这个例子里的平均复杂度分析其实并不需要这么复杂，不需要引入概率论的知识。
这是为什么呢？我们先来对比一下这个 `insert()` 的例子和前面那个 `find()` 的例子，就会发现这两者有很大差别。

首先，`find()` 函数在极端情况下，复杂度才为 `O(1)`。但 `insert(`) 在大部分情况下，时间复杂度都为 `O(1)`。
只有个别情况下，复杂度才比较高，为 `O(n)`。这是 `insert()`第一个区别于 `find()` 的地方。

我们再来看第二个不同的地方。对于 `insert()` 函数来说，`O(1)` 时间复杂度的插入和 `O(n)` 时间复杂度的插入，
出现的频率是非常有规律的，而且有一定的前后时序关系，一般都是一个 `O(n)` 插入之后，紧跟着 `n-1` 个 `O(1)` 的插入操作，循环往复。

所以，针对这样一种特殊场景的复杂度分析，我们并不需要像之前讲平均复杂度分析方法那样，找出所有的输入情况及相应的发生概率，然后再计算加权平均值。

针对这种特殊的场景，我们引入了一种更加简单的分析方法：**摊还分析法**，通过摊还分析得到的时间复杂度我们起了一个名字，叫**均摊时间复杂度**。

还是继续看在数组中插入数据的这个例子。每一次 `O(n)` 的插入操作，都会跟着 `n-1` 次 `O(1)` 的插入操作，
所以把耗时多的那次操作均摊到接下来的 `n-1` 次耗时少的操作上，均摊下来，这一组连续的操作的均摊时间复杂度就是 `O(1)`。

这就是均摊分析的大致思路

对一个数据结构进行一组连续操作中，大部分情况下时间复杂度都很低，只有个别情况下时间复杂度比较高，而且这些操作之间存在前后连贯的时序关系，
这个时候，我们就可以将这一组操作放在一块儿分析，看是否能将较高时间复杂度那次操作的耗时，平摊到其他那些时间复杂度比较低的操作上。
而且，在能够应用均摊时间复杂度分析的场合，一般均摊时间复杂度就等于最好情况时间复杂度。

尽管很多数据结构和算法书籍都花了很大力气来区分平均时间复杂度和均摊时间复杂度，
但其实我个人认为，均摊时间复杂度就是一种特殊的平均时间复杂度，我们没必要花太多精力去区分它们。
所以最应该掌握的是它的分析方法，摊还分析。至于分析出来的结果是叫平均还是叫均摊，这只是个说法，并不重要。

再来分析一下下面这段代码的复杂度：

```js

// 全局变量，大小为10的数组array，长度len，下标i。
const array = new Array(10);
const len = 10;
let i = 0;

// 往数组中添加一个元素
function add( element) {
   if (i >= len) { // 数组空间不够了
     // 重新申请一个2倍大小的数组空间
     const new_array = new Array(len*2);
     // 把原来array数组中的数据依次copy到new_array
     for (int j = 0; j < len; ++j) {
       new_array[j] = array[j];
     }
     // new_array复制给array，array现在大小就是2倍len了
     array = new_array;
     len = 2 * len;
   }
   // 将element放到下标为i的位置，下标i加一
   array[i] = element;
   ++i;
}
```

答案是 最小是 O(1)，最大是 O(n)，均摊是 O(1)
每次扩容的数量都是原来的 2 倍，都是经历之前数组长度的次数再次进行扩容，所以完全被均摊开了。

引用：

【等差数列求和公式】推导来啦：
方法是倒序相加

Sn=1+2+3+……+(n-1)+n

Sn=n+(n-1)+(n-2)+……+2+1

将上下两式相加

2Sn=(1+n)+(2+n-1)+(3+n-2)+……+(n-1+2)+(n+1)=(n+1)+(n+1)+(n+1)+……+(n+1)+(n+1)

一共 n 项(n+1)

2Sn=n(n+1)

Sn=n(n+1)/2
